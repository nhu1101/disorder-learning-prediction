
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "052d85e1-3fcc-474f-9b95-98dc4ca5694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_with_thresholds(raw_preds, thresholds):\n",
    "    return np.where(raw_preds < thresholds[0], int(0),\n",
    "                    np.where(raw_preds < thresholds[1], int(1),\n",
    "                             np.where(raw_preds < thresholds[2], int(2), int(3))))\n",
    "\n",
    "def optimize_thresholds(y_true, raw_preds, start_vals=[0.5, 1.5, 2.5]):\n",
    "    def fun(thresholds, y_true, raw_preds):\n",
    "        rounded_preds = round_with_thresholds(raw_preds, thresholds)\n",
    "        return -cohen_kappa_score(y_true, rounded_preds, weights='quadratic')\n",
    "\n",
    "    res = minimize(fun, x0=start_vals, args=(y_true, raw_preds), method='Powell')\n",
    "    assert res.success\n",
    "    return res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0298b2c1-3636-484f-9301-62fbf85be2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weights(series):\n",
    "    # Create bins for the target variable and assign weights based on frequency\n",
    "    bins = pd.cut(series, bins=10, labels=False)\n",
    "    weights = bins.value_counts().reset_index()\n",
    "    weights.columns = ['target_bins', 'count']\n",
    "    weights['count'] = 1 / weights['count']\n",
    "    weight_map = weights.set_index('target_bins')['count'].to_dict()\n",
    "    weights = bins.map(weight_map)\n",
    "    return weights / weights.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fd95306-4316-4005-9576-f94dbef262ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(model_, data, features, score_col, index_col, cv, sample_weights=False, verbose=False):\n",
    "    \"\"\"\n",
    "    Perform cross-validation with a given model and compute the out-of-fold \n",
    "    predictions and Cohen's Kappa score for each fold.\n",
    "\n",
    "    Returns:\n",
    "    float: Mean Kappa score across all folds.\n",
    "    array: Out-of-fold score predictions for the entire dataset.\n",
    "    \"\"\"\n",
    "    kappa_scores = [] \n",
    "    oof_score_predictions = np.zeros(len(data))  \n",
    "\n",
    "    score_to_index_thresholds = base_thresholds  \n",
    "    thresholds = []\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(cv.split(data, data[index_col])):\n",
    "        X_train, X_val = data[features].iloc[train_idx], data[features].iloc[val_idx]\n",
    "        y_train_score = data[score_col].iloc[train_idx] \n",
    "        y_train_index = data[index_col].iloc[train_idx]\n",
    "        y_val_score = data[score_col].iloc[val_idx]      \n",
    "        y_val_index = data[index_col].iloc[val_idx]     \n",
    "        \n",
    "        # Train model with sample weights if provided\n",
    "        if sample_weights:\n",
    "            weights = calculate_weights(y_train_score)\n",
    "            model_.fit(X_train, y_train_score, sample_weight=weights)\n",
    "        else:\n",
    "            model_.fit(X_train, y_train_score)\n",
    "        \n",
    "        #Predict on train and val: \n",
    "        y_pred_train_score = model_.predict(X_train)\n",
    "        y_pred_val_score = model_.predict(X_val)\n",
    "        \n",
    "        oof_score_predictions[val_idx] = y_pred_val_score \n",
    "\n",
    "        # Find optimal threshold in sample \n",
    "        t_1 = optimize_thresholds(y_train_index, y_pred_train_score, start_vals=base_thresholds)\n",
    "        thresholds.append(t_1)\n",
    "\n",
    "        y_pred_val_index = round_with_thresholds(y_pred_val_score, t_1)\n",
    "\n",
    "        kappa_score = cohen_kappa_score(y_val_index, y_pred_val_index, weights='quadratic')\n",
    "        kappa_scores.append(kappa_score)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Fold {fold_idx}: Optimized Kappa Score = {kappa_score}\")\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"## Mean CV Kappa Score: {np.mean(kappa_scores)} ##\")\n",
    "        print(f\"## Std CV: {np.std(kappa_scores)}\")\n",
    "    \n",
    "    return np.mean(kappa_scores), oof_score_predictions, thresholds\n",
    "\n",
    "def n_cross_validate(model_, data, features, score_col, index_col, cv, seeds, sample_weights=False, verbose=False):\n",
    "    scores = []\n",
    "    for seed in seeds:\n",
    "        cv.random_state=seed\n",
    "        score, oof, _ = cross_validate(model_, data, features, score_col, index_col, cv, sample_weights=True, verbose=False)\n",
    "        scores.append(score)\n",
    "    return score, oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c5a268e-5eee-42e3-8e0b-aa1079c866e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, model_type, X, features, score_col, index_col, cv, sample_weights=False):\n",
    "    # Parameter space to explore if model is xgboost\n",
    "    if model_type == 'xgboost':\n",
    "        params = {\n",
    "            'objective': trial.suggest_categorical('objective', ['reg:tweedie', 'reg:pseudohubererror']),\n",
    "            'random_state': SEED,\n",
    "            'num_parallel_tree': trial.suggest_int('num_parallel_tree', 2, 30),\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n",
    "            'max_depth': trial.suggest_int('max_depth', 2, 4),\n",
    "            'learning_rate': trial.suggest_loguniform('learning_rate', 0.02, 0.05),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 0.8),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 0.8),\n",
    "            'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 1e-1),\n",
    "            'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 1e-1),\n",
    "        }\n",
    "        if params['objective'] == 'reg:tweedie':\n",
    "            params['tweedie_variance_power'] = trial.suggest_float('tweedie_variance_power', 1, 2)\n",
    "        model = XGBRegressor(**params, use_label_encoder=False)\n",
    "    \n",
    "    # Parameter space to explore if model is lightgbm\n",
    "    elif model_type == 'lightgbm':\n",
    "        params = {\n",
    "            'objective': trial.suggest_categorical('objective', ['poisson', 'tweedie', 'regression']),\n",
    "            'random_state': SEED,\n",
    "            'verbosity': -1,\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n",
    "            'max_depth': trial.suggest_int('max_depth', 2, 4),\n",
    "            'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.05),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 0.8),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 0.8),\n",
    "            'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 20, 100)\n",
    "        }\n",
    "        if params['objective'] == 'tweedie':\n",
    "            params['tweedie_variance_power'] = trial.suggest_float('tweedie_variance_power', 1, 2)\n",
    "        model = LGBMRegressor(**params)\n",
    "    \n",
    "    # Parameter space to explore if model is catboost\n",
    "    elif model_type == 'catboost':\n",
    "        params = {\n",
    "            'loss_function': trial.suggest_categorical('objective', ['Tweedie:variance_power=1.5', \n",
    "                                                                     'Poisson', 'RMSE']),\n",
    "            'random_state': SEED,\n",
    "            'iterations': trial.suggest_int('iterations', 100, 300),\n",
    "            'depth': trial.suggest_int('depth', 2, 4),\n",
    "            'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.05),\n",
    "            'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 1e-1),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 0.7),\n",
    "            'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
    "            'random_strength': trial.suggest_float('random_strength', 1e-3, 10.0),\n",
    "            'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 20, 60),\n",
    "        }\n",
    "        model = CatBoostRegressor(**params, verbose=0)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model_type: {model_type}\")\n",
    "        \n",
    "    seeds = [random.randint(1, 10000) for _ in range(20)]\n",
    "\n",
    "    score, _ = n_cross_validate(model, X, features, score_col, index_col, cv, seeds, sample_weights=True, verbose=True)\n",
    "\n",
    "    return score\n",
    "\n",
    "def run_optimization(X, features, score_col, index_col, model_type, n_trials=30, cv=None, sample_weights=False):\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(lambda trial: objective(trial, model_type, X, features, score_col, index_col, cv, sample_weights), \n",
    "                   n_trials=n_trials)\n",
    "    \n",
    "    print(f\"Best params for {model_type}: {study.best_params}\")\n",
    "    print(f\"Best score: {study.best_value}\")\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b7ce06-c91f-4414-870c-68c75172cbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace if subsets for features have been selected\n",
    "\n",
    "exclude = [\"PC_9\", \"PC_12\", \"Fitness_Endurance-Max_Stage\", \"Basic_Demos-Sex\", 'BMI_mean_norm', \"PC_11\", \"PC_8\", \"FGC_Zones_min\", 'Physical-Systolic_BP',\n",
    "           \"PC_4\", \"BIA-BIA_FMI\", \"BIA-BIA_LST\", \"Physical-Diastolic_BP\", 'BIA-BIA_ECW', 'Fitness_Endurance-Time_Mins', 'PAQ_C-PAQ_C_Total', 'PC_10',\n",
    "           'BIA-BIA_Fat', 'FFM_norm', 'PC_14', 'PC_7']\n",
    "\n",
    "reduced_features = [f for f in features if f not in exclude]\n",
    "\n",
    "lgb_features = reduced_features\n",
    "xgb_features = reduced_features\n",
    "cat_features = reduced_features\n",
    "print(len(reduced_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fd4abe6-c069-4bc6-8cc2-eb141c918b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for LGBM, XGB and CatBoost\n",
    "lgb_params = {\n",
    "    'objective': 'poisson', \n",
    "    'n_estimators': 295, \n",
    "    'max_depth': 4, \n",
    "    'learning_rate': 0.04505693066482616, \n",
    "    'subsample': 0.6042489155604022, \n",
    "    'colsample_bytree': 0.5021876720502726, \n",
    "    'min_data_in_leaf': 100\n",
    "}\n",
    "\n",
    "xgb_params = {'objective': 'reg:tweedie', 'num_parallel_tree': 12, 'n_estimators': 236, 'max_depth': 3, 'learning_rate': 0.04223740904479563, 'subsample': 0.7157264603586825, 'colsample_bytree': 0.7897918901977528, 'reg_alpha': 0.005335705058190553, 'reg_lambda': 0.0001897435318347022, 'tweedie_variance_power': 1.1393958601390142}\n",
    "\n",
    "xgb_params_2 = {\n",
    "    'objective': 'reg:tweedie', \n",
    "    'num_parallel_tree': 18, \n",
    "    'n_estimators': 175, \n",
    "    'max_depth': 3, \n",
    "    'learning_rate': 0.032620453423049305, \n",
    "    'subsample': 0.6155579670568023, \n",
    "    'colsample_bytree': 0.5988773292417443, \n",
    "    'reg_alpha': 0.0028895066837627205, \n",
    "    'reg_lambda': 0.002232531512636924, \n",
    "    'tweedie_variance_power': 1.1708678482038286\n",
    "}\n",
    "\n",
    "cat_params = {\n",
    "    'objective': 'RMSE', \n",
    "    'iterations': 238, \n",
    "    'depth': 4, \n",
    "    'learning_rate': 0.044523361750173816, \n",
    "    'l2_leaf_reg': 0.09301285673435761, \n",
    "    'subsample': 0.6902492783438681, \n",
    "    'bagging_temperature': 0.3007304771330199, \n",
    "    'random_strength': 3.562201626987314, \n",
    "    'min_data_in_leaf': 60\n",
    "}\n",
    "\n",
    "xtrees_params = {\n",
    "    'n_estimators': 500, \n",
    "    'max_depth': 15, \n",
    "    'min_samples_leaf': 20, \n",
    "    'bootstrap': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bf9be5-68ea-4a60-a858-c3338e3618e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb5a873-abaa-49d1-b298-bde907f394bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if optimize_params:\n",
    "    # LightGBM Optimization\n",
    "    lgb_params = run_optimization(train, lgb_features, 'PCIAT-PCIAT_Total', 'sii', 'lightgbm', n_trials=n_trials, cv=kf, sample_weights=True)\n",
    "\n",
    "    # XGBoost Optimization\n",
    "    xgb_params = run_optimization(train, xgb_features, 'PCIAT-PCIAT_Total', 'sii', 'xgboost', n_trials=n_trials, cv=kf, sample_weights=True)\n",
    "\n",
    "    # CatBoost Optimization\n",
    "    cat_params = run_optimization(train, cat_features, 'PCIAT-PCIAT_Total', 'sii', 'catboost', n_trials=n_trials, cv=kf, sample_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13426ab-e7c3-46b1-bc04-32c5aacd161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "lgb_model = LGBMRegressor(**lgb_params, random_state=SEED, verbosity=-1)\n",
    "xgb_model = XGBRegressor(**xgb_params, random_state=SEED, verbosity=0)\n",
    "xgb_model_2 = XGBRegressor(**xgb_params_2, random_state=SEED, verbosity=0)\n",
    "cat_model = CatBoostRegressor(**cat_params, random_state=SEED, verbose=0)\n",
    "xtrees_model = ExtraTreesRegressor(**xtrees_params, random_state=SEED)\n",
    "\n",
    "weights = calculate_weights(train['PCIAT-PCIAT_Total'])\n",
    "\n",
    "# Cross-validate LGBM model\n",
    "score_lgb, oof_lgb, lgb_thresholds = cross_validate(\n",
    "    lgb_model, train, lgb_features, 'PCIAT-PCIAT_Total', 'sii', kf, verbose=True, sample_weights=True\n",
    ")\n",
    "lgb_model.fit(train[lgb_features], train['PCIAT-PCIAT_Total'], sample_weight=weights)\n",
    "test_lgb = lgb_model.predict(test[lgb_features])\n",
    "\n",
    "# Cross-validate XGBoost model\n",
    "score_xgb, oof_xgb, xgb_thresholds = cross_validate(\n",
    "    xgb_model, train, xgb_features, 'PCIAT-PCIAT_Total', 'sii', kf, verbose=True, sample_weights=True\n",
    ")\n",
    "xgb_model.fit(train[xgb_features], train['PCIAT-PCIAT_Total'], sample_weight=weights)\n",
    "test_xgb = xgb_model.predict(test[xgb_features])\n",
    "\n",
    "# Cross-validate XGBoost model 2\n",
    "score_xgb_2, oof_xgb_2, xgb_2_thresholds = cross_validate(\n",
    "    xgb_model_2, train, xgb_features, 'PCIAT-PCIAT_Total', 'sii', kf, verbose=True, sample_weights=True\n",
    ")\n",
    "xgb_model_2.fit(train[xgb_features], train['PCIAT-PCIAT_Total'], sample_weight=weights)\n",
    "test_xgb_2 = xgb_model_2.predict(test[xgb_features])\n",
    "\n",
    "# Cross-validate CatBoost model\n",
    "score_cat, oof_cat, cat_thresholds = cross_validate(\n",
    "    cat_model, train, cat_features, 'PCIAT-PCIAT_Total', 'sii', kf, verbose=True, sample_weights=True\n",
    ")\n",
    "cat_model.fit(train[cat_features], train['PCIAT-PCIAT_Total'], sample_weight=weights)\n",
    "test_cat = cat_model.predict(test[cat_features])\n",
    "\n",
    "# Cross-validate ExtraTreesRegressor model\n",
    "score_xtrees, oof_xtrees, xtrees_thresholds = cross_validate(\n",
    "    xtrees_model, train, reduced_features, 'PCIAT-PCIAT_Total', 'sii', kf, verbose=True, sample_weights=True\n",
    ")\n",
    "xtrees_model.fit(train[reduced_features], train['PCIAT-PCIAT_Total'], sample_weight=weights)\n",
    "test_xtrees = xtrees_model.predict(test[reduced_features])\n",
    "\n",
    "# Print overall mean Kappa score for all models\n",
    "print(f'Overall Mean Kappa: {np.mean([score_lgb, score_xgb, score_cat, score_xtrees])}') # Ensemble score likely higher"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
